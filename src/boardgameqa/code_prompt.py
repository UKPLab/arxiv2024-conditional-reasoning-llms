import random

from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate
from langchain.schema import StrOutputParser

from .evaluation import Answer


class CodePrompt:
    """
    A class for code prompting for BoardgameQA dataset.

    Attributes:
    - icl_examples (list): List of demonstrations.
    - llm: The large language model used for interpretation and translation.
    - num_translation_demonstrations (int): Number of translation demonstrations.
    - num_interpreter_demonstrations (int): Number of interpreter demonstrations.
    - seed (int): Seed for random number generation.

    Methods:
    - __init__: Initializes the BoardgameQA_CodePrompt object.
    - __call__: Executes the code prompt.
    - _create_interpreter_chain: Creates the interpreter chain for the code prompt (2nd step in the pipeline).
    - _create_translation_chain: Creates the translation chain for the code prompt (1st step in the pipeline).
    - _create_icl_demos_partitions: Creates partitions for interpreter demonstrations.
    - extract_question: Extracts the question from an example.
    - create_input_text: Creates the input text for the code prompt.
    - process_response: Processes the response from the code prompt.
    """

    def __init__(
        self,
        icl_examples,
        llm,
        num_translation_demonstrations=4,
        num_interpreter_demonstrations=4,
        seed=42,
    ):
        self.icl_examples = icl_examples
        self.num_translation_demonstrations = num_translation_demonstrations
        self.num_interpreter_demonstrations = num_interpreter_demonstrations
        self.llm = llm
        random.seed(seed)
        self.translation_chain = self._create_translation_chain()
        (
            self.interpreter_chain,
            self.interpreter_prompt_template,
        ) = self._create_interpreter_chain()

    def __call__(self, input_example=None, input_code=None):
        """
        Executes the code prompt.

        Args:
        - input_example: The input example for the code prompt.
        - input_code: The input code for the code prompt.

        Returns:
        - proof: The proof generated by the code prompt.
        - input_code: The input code used by the code prompt.
        - interpreter_prompt_input: The interpreter prompt input used by the code prompt.
        """
        if input_code is None:
            if input_example is None:
                raise ValueError("Either input_example or input_code must be provided")
            input_code = self.translation_chain.invoke({"input": input_example})
        proof = self.interpreter_chain.invoke({"input": input_code})
        interpreter_prompt_input = self.interpreter_prompt_template.format_messages(
            input=input_code
        )
        return proof, input_code, interpreter_prompt_input

    def _create_interpreter_chain(self):
        """
        Creates the interpreter chain for the code prompt.

        Returns:
        - chain: The interpreter chain.
        - final_prompt: The final prompt for the code prompt.
        """
        examples = []
        self.interpreter_demonstrations = self._create_icl_demos_partitions()
        for x in self.interpreter_demonstrations:
            examples.append({"input": x["input_code"], "output": x["proof_code"]})

        # This is a prompt template used to format each individual example.
        example_prompt = ChatPromptTemplate.from_messages(
            [
                ("human", "{input}"),
                ("ai", "{output}"),
            ]
        )
        few_shot_prompt = FewShotChatMessagePromptTemplate(
            example_prompt=example_prompt,
            examples=examples,
        )

        final_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "You are a large language model of code that can interpret code. You are given a pseudo-code that resembles to first-order logic that models some scenario. You will be given a question and you have to answer it step by step. You can use a rule if and only if you know the antecedent of the rule.",
                ),
                few_shot_prompt,
                ("human", "{input}"),
            ]
        )
        chain = final_prompt | self.llm | StrOutputParser()
        return chain, final_prompt

    def _create_translation_chain(self):
        """
        Creates the translation chain for the code prompt.

        Returns:
        - chain: The translation chain.
        """
        examples = []
        self.translation_demonstrations = random.sample(
            self.icl_examples, self.num_translation_demonstrations
        )
        for x in self.translation_demonstrations:
            examples.append({"input": x["input_text"], "output": x["input_code"]})

        # This is a prompt template used to format each individual example.
        example_prompt = ChatPromptTemplate.from_messages(
            [
                ("human", "{input}"),
                ("ai", "{output}"),
            ]
        )
        few_shot_prompt = FewShotChatMessagePromptTemplate(
            example_prompt=example_prompt,
            examples=examples,
        )

        final_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "You are a large language model of code that can translate natural language text into code. Your job is to make code that models the scenario described in the text. You do not have to solve the question written in the text. The code describing the current state of the game should correspond to the code describing the rules of the game.",
                ),
                few_shot_prompt,
                ("human", "{input}"),
            ]
        )
        chain = final_prompt | self.llm | StrOutputParser()
        return chain

    def _create_icl_demos_partitions(self):
        """
        Creates partitions for interpreter demonstrations.

        Returns:
        - demos: The list of interpreter demonstrations.
        """
        proved = []
        disproved = []
        unknown = []
        for x in self.icl_examples:
            if x["label"] == "proved":
                proved.append(x)
            elif x["label"] == "disproved":
                disproved.append(x)
            else:
                unknown.append(x)
        num_demos_per_class = self.num_interpreter_demonstrations / 3
        remainder_demos = self.num_interpreter_demonstrations % 3
        demos = (
            random.sample(proved, int(num_demos_per_class))
            + random.sample(disproved, int(num_demos_per_class))
            + random.sample(unknown, int(num_demos_per_class))
            + random.sample(self.icl_examples, remainder_demos)
        )
        random.shuffle(demos)
        return demos

    def extract_question(self, example):
        """
        Extracts the question from an example.

        Args:
        - example: The example containing the question.

        Returns:
        - question: The extracted question.
        """
        question = example.split(
            "Based on the game state and the rules and preferences, "
        )[1]
        return question

    def create_input_text(self, data_point):
        """
        Creates the input text for the code prompt.

        Args:
        - data_point: The data point containing the necessary information.

        Returns:
        - input_text: The created input text.
        """
        input_text = (
            "A few players are playing a boardgame\nThe rules of the game are as follows\n"
            + "\n".join(data_point["rules"].split(". "))
            + "\n"
            + "\n".join(data_point["preferences"].split(". "))
            + "\nThe current state of the game is as follows\n"
            + "\n".join(data_point["facts"].split(". "))
            + "\n\nBased on the game state and the rules and preferences, "
            + self.extract_question(data_point["example"])
        )
        return input_text

    def process_response(self, response):
        """
        Processes the response from the code prompt.

        Args:
        - response: The response from the code prompt.

        Returns:
        - answer: The processed answer.
        """
        answer = Answer.UNKNOWN
        if "True" in response.split("\n")[-1]:
            answer = Answer.YES
        elif "False" in response.split("\n")[-1]:
            answer = Answer.NO
        return answer
